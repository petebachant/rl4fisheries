# algo 
algo: "TQC"
total_timesteps: 10000000
algo_config:
    tensorboard_log: "../../../logs"
    policy: 'MlpPolicy'
    # learning_rate: !!float 7.3e-4
    # buffer_size: 500000
    # batch_size: 512
    # ent_coef: 'auto'
    # gamma: 0.98
    # tau: 0.02
    # train_freq: 64
    # gradient_steps: 64
    # learning_starts: 30000
    use_sde: True
    # policy_kwargs: "dict(log_std_init=-3, net_arch=[128, 64])"

# env
env_id: "AsmEnv"
config: 
    observation_fn_id: 'observe_2o'
    n_observs: 2
    harvest_fn_name: "trophy"
    n_trophy_ages: 10
    # upow: 0.6
    # use_custom_harv_vul: True
    # use_custom_surv_vul: True
n_envs: 12

# io
repo: "cboettig/rl-ecology"
save_path: "../saved_agents/results"

# misc
id: "results-trophy-nage-10"
additional_imports: ["torch"]
